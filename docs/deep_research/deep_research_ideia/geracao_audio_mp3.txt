# PESQUISA TÉCNICA PROFUNDA: PIPELINE COMPLETO DE GERAÇÃO DE ÁUDIO MP3

## MODELOS DE GERAÇÃO DE ÁUDIO NO REPLICATE

### stackadoc/stable-audio-open-1.0

O Stable Audio Open 1.0 é um modelo de difusão latente otimizado para geração de amostras de áudio curtas, efeitos sonoros e elementos de produção usando prompts de texto[1]. O modelo gera áudio estéreo de comprimento variável (até 47 segundos) a 44.1kHz, sendo ideal para criar batidas de bateria, riffs de instrumentos, sons ambiente e gravações foley[2].

**Parâmetros de API:**
- `prompt` (string): Descrição textual do áudio desejado
- `seconds_total` (integer): Duração total em segundos (padrão: 8)
- `seconds_start` (integer): Tempo de início
- `cfg_scale` (number): Escala de orientação (padrão: 6)
- `steps` (integer): Passos de difusão (padrão: 100)
- `seed` (integer): Semente para geração (padrão: -1)
- `sampler_type` (string): Tipo de amostrador (padrão: "dpmpp-3m-sde")
- `sigma_min` (number): Valor mínimo sigma (padrão: 0.03)
- `sigma_max` (integer): Valor máximo sigma (padrão: 500)[3]

**Formato de saída:** URI para arquivo de áudio WAV em 44.1kHz estéreo[4]

### meta/musicgen

O MusicGen é um modelo Transformer auto-regressivo de estágio único treinado com um tokenizador EnCodec de 32kHz com 4 codebooks amostrados a 50 Hz[5]. Oferece duas versões: Melody (1.5 bilhões de parâmetros) que aceita prompts de texto e áudio, e Large (3.5 bilhões de parâmetros) apenas com prompts de texto[5].

**Parâmetros de API:**
- `prompt` (string): Descrição da música desejada
- `duration` (integer): Duração em segundos (padrão: 8)
- `model_version` (string): Versão do modelo (padrão: "stereo-melody-large")
- `output_format` (string): Formato de saída (padrão: "wav")
- `normalization_strategy` (string): Estratégia de normalização (padrão: "loudness")
- `top_k` (integer): Reduz amostragem aos k tokens mais prováveis (padrão: 250)
- `top_p` (number): Amostragem com probabilidade cumulativa
- `temperature` (number): Controla conservadorismo da amostragem (padrão: 1)
- `classifier_free_guidance` (integer): Influência dos inputs na saída (padrão: 3)[6]

### lucataco/magnet

O MAGNeT é um modelo de geração de áudio texto-para-música e texto-para-som capaz de gerar amostras de alta qualidade usando um Transformer não-autoregressivo mascarado[7]. Utiliza um tokenizador EnCodec de 32kHz com 4 codebooks amostrados a 50 Hz[7].

**Parâmetros de API:**
- `prompt` (string): Texto de entrada (padrão: "80s electronic track with melodic synthesizers, catchy beat and groovy bass")
- `model` (string): Modelo a usar (opções: facebook/magnet-small-10secs, facebook/magnet-medium-10secs, etc.)
- `variations` (integer): Número de variações (1-4, padrão: 3)
- `span_score` (string): Pontuação de span (opções: max-nonoverlap, prod-stride1)
- `temperature` (number): Temperatura para amostragem (padrão: 3)
- `top_p` (number): Top p para amostragem (padrão: 0.9)
- `max_cfg` (number): Coeficiente CFG máximo (padrão: 10)
- `min_cfg` (number): Coeficiente CFG mínimo (padrão: 1)
- Passos de decodificação para 4 estágios (padrão: 20, 10, 10, 10)[8]

## PROCESSAMENTO E CONVERSÃO DE ÁUDIO

### PyDub com FFmpeg

O PyDub é a biblioteca Python mais eficaz para manipulação de áudio, oferecendo suporte nativo a WAV e requerendo FFmpeg para formatos como MP3[9]. Para normalização de áudio, o PyDub fornece métodos para ajustar o volume baseado em dBFS[10][11].

**Normalização para -3dB:**
```python
def normalize_to_peak(audio, target_db=-3.0):
    current_peak_db = audio.max_dBFS
    gain_needed = target_db - current_peak_db
    return audio.apply_gain(gain_needed)
```

**Fade In/Out:**
O PyDub possui métodos integrados `fade_in()` e `fade_out()` que permitem especificar a duração em milissegundos[12]. Para 10ms de fade:
```python
audio = audio.fade_in(10).fade_out(10)
```

**Conversão para MP3 com Especificações Exatas:**
```python
audio.export(
    "output.mp3",
    format="mp3",
    bitrate="128k",
    parameters=["-ac", "2", "-ar", "44100"]
)
```

### Criação de Loops Seamless

Para o arquivo `processing_loop.mp3`, é necessário criar um loop perfeito sem interrupções audíveis[13][14]. A técnica mais eficaz utiliza crossfading entre o final e o início do áudio:

```python
def create_seamless_loop(audio, crossfade_duration=100):
    start_portion = audio[:crossfade_duration]
    end_portion = audio[-crossfade_duration:]
    middle_portion = audio[crossfade_duration:-crossfade_duration]
    
    crossfaded = end_portion.append(start_portion, crossfade=crossfade_duration)
    seamless_loop = start_portion + middle_portion + crossfaded[crossfade_duration:]
    
    return seamless_loop
```

Bibliotecas especializadas como PyMusicLooper podem automatizar a detecção de pontos de loop ideais usando correlação para encontrar transições suaves[15][16].

## CÓDIGO PYTHON COMPLETO

### Implementação da Classe Principal

```python
import replicate
import requests
import os
from pydub import AudioSegment
import tempfile

class AudioEffectGenerator:
    def __init__(self, replicate_token: str):
        os.environ['REPLICATE_API_TOKEN'] = replicate_token
        self.client = replicate.Client(api_token=replicate_token)
    
    def generate_sound_effect(self, prompt: str, duration: float, 
                            output_filename: str, model_choice: str = "stable-audio") -> str:
        """
        Gera efeito sonoro usando modelos Replicate e processa para especificações MP3.
        """
        # 1. Chamar Replicate API
        raw_audio_url = self._call_replicate_model(prompt, duration, model_choice)
        
        # 2. Baixar arquivo gerado
        temp_file = self._download_audio(raw_audio_url)
        
        # 3. Converter/processar conforme specs
        processed_file = self._process_audio(temp_file, output_filename, duration)
        
        # 4. Limpar arquivos temporários
        os.unlink(temp_file)
        
        return processed_file
    
    def _call_replicate_model(self, prompt: str, duration: float, model_choice: str) -> str:
        """Chama o modelo Replicate apropriado."""
        
        if model_choice == "stable-audio":
            output = self.client.run(
                "stackadoc/stable-audio-open-1.0",
                input={
                    "prompt": prompt,
                    "seconds_total": int(duration),
                    "seconds_start": 0,
                    "cfg_scale": 6,
                    "steps": 100,
                    "seed": -1,
                    "sampler_type": "dpmpp-3m-sde",
                    "sigma_min": 0.03,
                    "sigma_max": 500,
                    "batch_size": 1
                }
            )
        
        elif model_choice == "musicgen":
            output = self.client.run(
                "meta/musicgen",
                input={
                    "prompt": prompt,
                    "duration": int(duration),
                    "model_version": "stereo-melody-large",
                    "output_format": "wav",
                    "normalization_strategy": "loudness",
                    "top_k": 250,
                    "temperature": 1,
                    "classifier_free_guidance": 3
                }
            )
        
        elif model_choice == "magnet":
            output = self.client.run(
                "lucataco/magnet",
                input={
                    "prompt": prompt,
                    "model": "facebook/magnet-small-10secs" if duration  str:
        """Baixa áudio da URL para arquivo temporário."""
        response = requests.get(url)
        response.raise_for_status()
        
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_file:
            temp_file.write(response.content)
            return temp_file.name
    
    def _process_audio(self, input_file: str, output_filename: str, target_duration: float) -> str:
        """
        Processa áudio para atender especificações:
        - Formato: MP3, 44.1kHz, Estéreo, 128 kbps CBR
        - Normalização: -3dB peak
        - Fade: 10ms in/out
        """
        audio = AudioSegment.from_file(input_file)
        
        # Garantir estéreo
        if audio.channels == 1:
            audio = audio.set_channels(2)
        
        # Definir taxa de amostragem 44.1kHz
        audio = audio.set_frame_rate(44100)
        
        # Ajustar duração
        target_duration_ms = int(target_duration * 1000)
        if len(audio) > target_duration_ms:
            audio = audio[:target_duration_ms]
        elif len(audio)  0:
                loops_needed = (target_duration_ms // len(audio)) + 1
                audio = audio * loops_needed
                audio = audio[:target_duration_ms]
        
        # Normalizar para -3dB peak
        audio = self._normalize_to_peak(audio, -3.0)
        
        # Aplicar fade 10ms
        audio = audio.fade_in(10).fade_out(10)
        
        # Exportar como MP3 com especificações exatas
        audio.export(
            output_filename,
            format="mp3",
            bitrate="128k",
            parameters=["-ac", "2", "-ar", "44100"]
        )
        
        return output_filename
    
    def _normalize_to_peak(self, audio: AudioSegment, target_db: float) -> AudioSegment:
        """Normaliza áudio para nível de pico específico em dB."""
        current_peak_db = audio.max_dBFS
        gain_needed = target_db - current_peak_db
        return audio.apply_gain(gain_needed)
    
    def create_seamless_loop(self, input_file: str, output_file: str, 
                           loop_duration: float = 3.0) -> str:
        """
        Cria loop seamless para processing_loop.mp3 usando crossfade.
        """
        audio = AudioSegment.from_file(input_file)
        
        crossfade_duration = 100  # 100ms crossfade
        loop_duration_ms = int(loop_duration * 1000)
        
        if len(audio) >= loop_duration_ms:
            loop_audio = audio[:loop_duration_ms]
        else:
            loops_needed = (loop_duration_ms // len(audio)) + 1
            loop_audio = audio * loops_needed
            loop_audio = loop_audio[:loop_duration_ms]
        
        # Criar loop seamless com crossfade
        start_portion = loop_audio[:crossfade_duration]
        end_portion = loop_audio[-crossfade_duration:]
        middle_portion = loop_audio[crossfade_duration:-crossfade_duration]
        
        crossfaded = end_portion.append(start_portion, crossfade=crossfade_duration)
        seamless_loop = start_portion + middle_portion + crossfaded[crossfade_duration:]
        
        # Aplicar mesmo processamento dos outros efeitos
        seamless_loop = seamless_loop.set_frame_rate(44100).set_channels(2)
        seamless_loop = self._normalize_to_peak(seamless_loop, -3.0)
        seamless_loop = seamless_loop.fade_in(10).fade_out(10)
        
        seamless_loop.export(
            output_file,
            format="mp3",
            bitrate="128k",
            parameters=["-ac", "2", "-ar", "44100"]
        )
        
        return output_file
```

### Exemplo de Uso Completo

```python
def main():
    # Inicializar gerador
    generator = AudioEffectGenerator("your_replicate_token_here")
    
    # Definições dos efeitos sonoros com prompts otimizados
    sound_effects = [
        {
            "filename": "button_tap.mp3",
            "duration": 0.5,
            "prompt": "soft gentle button click UI sound, pleasant interface feedback, short"
        },
        {
            "filename": "success.mp3", 
            "duration": 1.5,
            "prompt": "cheerful success bell chime, pleasant notification, achievement sound"
        },
        {
            "filename": "error_gentle.mp3",
            "duration": 1.0,
            "prompt": "gentle error sound, soft musical warning, kind notification"
        },
        {
            "filename": "notification.mp3",
            "duration": 1.0,
            "prompt": "gentle notification bell, soft chime, pleasant alert sound"
        },
        {
            "filename": "achievement.mp3",
            "duration": 2.5,
            "prompt": "celebratory fanfare, achievement fanfare, success celebration music"
        },
        {
            "filename": "camera_shutter.mp3",
            "duration": 0.5,
            "prompt": "camera shutter click, photo capture sound, mechanical click"
        },
        {
            "filename": "page_transition.mp3",
            "duration": 0.5,
            "prompt": "swoosh transition sound, page turn, smooth movement sound"
        },
        {
            "filename": "pop_up.mp3",
            "duration": 0.5,
            "prompt": "bubble pop sound, playful pop, light bubble burst"
        }
    ]
    
    # Gerar todos os efeitos sonoros
    for effect in sound_effects:
        print(f"Gerando {effect['filename']}...")
        generator.generate_sound_effect(
            prompt=effect['prompt'],
            duration=effect['duration'],
            output_filename=effect['filename'],
            model_choice="stable-audio"  # ou "musicgen" ou "magnet"
        )
    
    # Gerar processing_loop.mp3 separadamente
    print("Gerando processing_loop.mp3...")
    temp_loop = generator.generate_sound_effect(
        prompt="ambient processing sound, soft background loop, gentle electronic hum",
        duration=3.0,
        output_filename="temp_processing.mp3"
    )
    
    # Criar versão seamless
    generator.create_seamless_loop("temp_processing.mp3", "processing_loop.mp3", 3.0)
    os.unlink("temp_processing.mp3")  # Limpar arquivo temporário

if __name__ == "__main__":
    main()
```

## RECOMENDAÇÕES PARA QUALIDADE INFANTIL

Para aplicações infantis educacionais, recomenda-se priorizar o modelo **stable-audio-open-1.0** devido à sua capacidade superior de gerar efeitos sonoros específicos e controle preciso de duração[1]. Os prompts devem enfatizar características como "gentle", "soft", "pleasant" e "kind" para garantir sons apropriados para crianças[17].

A implementação apresentada garante conformidade total com as especificações técnicas obrigatórias, incluindo processamento automático para MP3 128kbps CBR estéreo a 44.1kHz, normalização para -3dB peak e fade de 10ms[9][18]. O sistema de loop seamless assegura reprodução contínua sem artefatos audíveis para o arquivo de processamento[13][14].

[1] https://replicate.com/stackadoc/stable-audio-open-1.0
[2] https://huggingface.co/stabilityai/stable-audio-open-1.0
[3] https://replicate.com/stackadoc/stable-audio-open-1.0/api/schema
[4] https://www.aimodels.fyi/models/replicate/stable-audio-open-10-stackadoc
[5] https://replicate.com/meta/musicgen/api
[6] http://arxiv.org/pdf/2412.11907.pdf
[7] https://huggingface.co/facebook/magnet-small-10secs
[8] https://arxiv.org/pdf/2409.09546.pdf
[9] https://github.com/travnick/audio-normalize
[10] https://stackoverflow.com/questions/42492246/how-to-normalize-the-volume-of-an-audio-file-in-python
[11] https://www.reddit.com/r/learnpython/comments/9zw33b/how_do_i_set_a_rms_threshold_for_audio/
[12] https://www.programmersought.com/article/1681293418/
[13] https://nolannicholson.com/2019/10/27/looping-music-seamlessly.html
[14] https://www.reddit.com/r/Python/comments/91ih6r/how_to_find_seamless_loops_in_audio_files_with_a/
[15] https://docsbot.ai/prompts/technical/seamless-audio-loop-creator
[16] https://blog.argentgames.co/post/2020-11-16-renpy-crossfade-music/
[17] https://replicate.com/docs/get-started/python
[18] https://www.astateofdata.com/python-programming/ffmpeg-python/
[19] https://www.mdpi.com/2313-7673/9/11/687
[20] https://dl.acm.org/doi/10.1145/3613905.3650785
[21] https://ieeexplore.ieee.org/document/10731578/
[22] https://arxiv.org/abs/2301.12503
[23] https://arxiv.org/abs/2301.12661
[24] https://arxiv.org/abs/2406.00356
[25] https://arxiv.org/abs/2308.09300
[26] https://arxiv.org/abs/2410.11299
[27] https://replicate.com/collections/ai-music-generation
[28] https://replicate.com/zsxkib/mmaudio
[29] https://replicate.com/collections/ai-enhance-audio
[30] https://replicate.com/collections/text-to-speech
[31] https://replicate.com/blog/how-to-tune-a-realistic-voice-clone
[32] https://musicgenai.org/musicgen-api/
[33] https://github.com/replicate/cog-musicgen
[34] https://www.aimodels.fyi/models/replicate/stable-audio-prod-ardianfe
[35] https://ieeexplore.ieee.org/document/10289641/
[36] https://www.semanticscholar.org/paper/13a0d8bb38f739990c8cd65a44061c6534f17221
[37] https://ieeexplore.ieee.org/document/10096873/
[38] https://www.ijraset.com/best-journal/gennarrate-ai-powered-story-synthesis-with-visual-and-audio-outputs
[39] https://f1000research.com/articles/5-189/v1
[40] https://arxiv.org/abs/2401.12570
[41] https://dx.plos.org/10.1371/journal.pone.0325284
[42] https://www.science.org/doi/10.1126/sciadv.adv2052
[43] https://replicate.com/stackadoc/stable-audio-open-1.0/api
[44] https://replicate.com/stackadoc/stable-audio-open-1.0/readme
[45] https://replicate.com/stackadoc/stable-audio-open-1.0/api/learn-more
[46] https://aimlapi.com/models/stable-audio
[47] https://www.digitalocean.com/community/tutorials/stable-audio-music-generation
[48] https://arxiv.org/abs/2505.03332
[49] https://replicate.com/meta/musicgen
[50] https://replicate.com/meta/musicgen/api/api-reference
[51] https://replicate.com/meta/musicgen/api/schema
[52] https://comfy.icu/node/Replicate-lucataco-magnet
[53] https://github.com/jiaaro/pydub
[54] https://replicate.com/lucataco/magnet/versions/e8e2ecd4a1dabb58924aa8300b668290cafae166dd36baf65dad9875877de50e/api
[55] https://arxiv.org/pdf/1912.05472.pdf
[56] https://arxiv.org/pdf/2310.11364.pdf
[57] http://arxiv.org/pdf/2206.12513.pdf
[58] http://arxiv.org/pdf/2210.13438v1.pdf
[59] https://arxiv.org/html/2501.02293v2
[60] https://arxiv.org/pdf/2403.09789.pdf
[61] https://github.com/jiaaro/pydub/issues/90
[62] https://stackoverflow.com/questions/78257749/sound-fade-in-fade-out-algorithm
[63] https://github.com/angelo234/fade-in-out-audio-loops
[64] https://arxiv.org/abs/2501.04116
[65] https://hstalks.com/doi/10.69554/AIML1271/
[66] https://ijsrem.com/download/audio-extraction-from-a-video/
[67] https://imanagerpublications.com/article/20486
[68] http://www.stemmpress.com/jbdc/jbdc20233/375.html
[69] https://ieeexplore.ieee.org/document/11011374/
[70] https://dl.acm.org/doi/10.1145/2964284.2973795
[71] https://ijsrem.com/download/video-steganography-using-machine-learning-with-python/
[72] https://transloadit.com/devtips/looping-audio-in-python-techniques-for-seamless-playback/
[73] https://github.com/arkrow/PyMusicLooper
[74] https://pypi.org/project/pymusiclooper/
[75] https://stackoverflow.com/questions/46926033/create-seamless-loop-of-audio-web/47477162
[76] https://snyk.io/advisor/python/pydub/functions/pydub.AudioSegment.silent
[77] https://www.semanticscholar.org/paper/61632c78b26ca366b5a1c8cbf3d0f50981126e8e
[78] https://ieeexplore.ieee.org/document/10657162/
[79] https://link.springer.com/10.1007/s12145-023-01086-5
[80] http://hdl.handle.net/1853/66345
[81] https://community.pickaxeproject.com/t/meta-musicgen-controls-how-generate-longer-music/3652
[82] https://arxiv.org/pdf/2311.10113.pdf
[83] https://arxiv.org/pdf/2211.13956.pdf
[84] https://www.djbajablast.com/post/use-python-to-automate-audio-sample-processing-via-pydub
[85] https://discuss.streamlit.io/t/normalize-audio-using-pydub-and-load-it-on-streamlit-audio-player/13574
[86] https://github.com/jiaaro/pydub/issues/340
[87] https://www.emerald.com/insight/content/doi/10.1108/LHTN-07-2024-0111/full/html
[88] https://arxiv.org/abs/2503.17866
[89] https://processing.org/reference/libraries/sound/soundfile_loop_